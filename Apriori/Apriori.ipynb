{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries we will need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) A drawback of using confidence is that it ignores Pr(B). Why is this a drawback? Explain\n",
    "why lift and conviction do not suffer from this drawback.(15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    当Pr(B)过高时，B是否出现与A的关系就不那么强，但是confidence依然很高，因此出现误导，不能说明两者的相关性。但lift和conviction会计算S(B)，相当于考虑到了Pr（B），并且lift和conviction的定义中，提到了A和B需要互相独立这一前提条件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) A measure is symmetrical if measure(A → B) = measure(B → A). Which of the measures presented here are symmetrical? For each measure, please provide either a proof that the measure is symmetrical, or a counterexample that shows the measure is not symmetrical.(15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Lift is symmetrical.\n",
    "\n",
    "    Lift: \n",
    "    lift(A->B) = conf(A->B)/S(B) = Pr(B|A)/S(B) = S(AB)/S(A)S(B)\n",
    "    同理lift(B->A) = S(AB)/S(B)S(A) = lift(A->B).\n",
    "\n",
    "    反例：\n",
    "    Confidence: \n",
    "    假设Pr(A) = 1 且 Pr(B) ≠ 1\n",
    "    则conf(B->A) = 1\n",
    "    且conf(A->B) = Pr(B)≠1\n",
    "    conf(B->A) ≠ conf(A->B).\n",
    "\n",
    "    Conviction:\n",
    "    假设S(A) = 1，S(B)  =0.5\n",
    "    则conf(A->B) = Pr(B|A) = 0.5, conf(B->A) = Pr(A|B) = 1\n",
    "    conv(A->B) = (1-S(B))/(1-conf(A->B)) = 1\n",
    "    conv(B->A) = (1-S(A))/(1-conf(B->A)) = 0\n",
    "    conv(B->A) ≠ conv(A->B)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Perfect implications are rules that hold 100% of the time (or equivalently, the associated conditional probability is 1). A measure is desirable if it reaches its maximum achievable value for all perfect implications. This makes it easy to identify the best rules. Which of the above measures have this property? You may ignore 0/0 but not other infinity cases. Also you may find it easy to explain by an example.(20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    confidence：\n",
    "    有这个性质。对任意perfect implication，conf都能取到最大值1.\n",
    "\n",
    "    lift：\n",
    "    没有这个性质。反例：假如A和B每次都会同时出现，则conf(A->B)=conf(B->A)=1,且S(B)=1，所以lift(A->B)=1\n",
    "\n",
    "    conv：\n",
    "    有这个性质。对任意perfect implication,1-conf(A->B)会取到零，conv则取到正无穷，为其最大值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) [20pts]\n",
    "Identify pairs of items (X, Y ) such that the support of {X, Y } is at least 100 . For all such pairs, compute the confidence scores of the corresponding association rules: X -> Y,Y -> X. Sort the rules in decreasing order of confidence scores and list the top 5 rules in the writeup. Break ties, if any, by lexicographically increasing order on the left hand side of the rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=[]\n",
    "with open(\"browsing.txt\",\"r\") as f: \n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        temp = line.split()\n",
    "        dataset.append(temp)\n",
    "        \n",
    "dataset = list(map(frozenset,dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "item1 = set(itertools.chain(*dataset))\n",
    "C1 = [frozenset([i]) for i in sorted(item1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LK(dataset,CK,support_min):\n",
    "    support = {}\n",
    "    for row in dataset:\n",
    "        for item in CK:\n",
    "            if item.issubset(row):\n",
    "                support[item] = support.get(item,0)+1\n",
    "    return {k : v for k,v in support.items() if v >= support_min}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = LK(dataset,C1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(LK):\n",
    "    CK = []\n",
    "    lenLk = len(LK)\n",
    "    k = len(LK[0])+1\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1,lenLk):\n",
    "            L1 = list(LK[i])[:k-2]\n",
    "            L2 = list(LK[j])[:k-2]\n",
    "            L1.sort()\n",
    "            L2.sort()\n",
    "            if L1 == L2:\n",
    "                CK.append(LK[i] | LK[j])\n",
    "    return CK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "C2 = apriori(list(L1.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2 = LK(dataset,C2,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule(item):\n",
    "    left=[]\n",
    "    for i in range(1,len(item)):\n",
    "        left.extend(itertools.combinations(item,i))\n",
    "    return [(frozenset(r),frozenset(item.difference(r))) for r in left]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_result(supportData):\n",
    "    rules=[]\n",
    "    for item in supportData:\n",
    "        if len(item) >= 1:\n",
    "            rules.extend(rule(item))\n",
    "    result=[]\n",
    "    for left,right in rules:      \n",
    "        conf = supportData[left|right] / supportData[left]\n",
    "        result.append([left,right,conf])\n",
    "    result = sorted(result,key=(lambda x:(x[2],x[0])),reverse=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[frozenset({'DAI93865'}), frozenset({'FRO40251'}), 1.0],\n",
       " [frozenset({'GRO85051'}), frozenset({'FRO40251'}), 0.999176276771005],\n",
       " [frozenset({'GRO38636'}), frozenset({'FRO40251'}), 0.9906542056074766],\n",
       " [frozenset({'ELE12951'}), frozenset({'FRO40251'}), 0.9905660377358491],\n",
       " [frozenset({'DAI88079'}), frozenset({'FRO40251'}), 0.9867256637168141]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supportData_2={}\n",
    "for i,j in L2.items():\n",
    "    supportData_2[i] = j\n",
    "for i,j in L1.items():\n",
    "    supportData_2[i] = j\n",
    "\n",
    "conf2 = conf_result(supportData_2)\n",
    "conf2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) [30pts] Identify item triples (X, Y, Z) such that the support of {X, Y, Z} is at least 100. For all such triples, compute the confidence scores of the corresponding association rules: (X, Y ) ⇒ Z,(X, Z) ⇒ Y , (Y, Z) ⇒ X. Sort the rules in decreasing order of confidence scores and list the top 5 rules in the writeup. Order the left-hand-side pair lexicographically and break ties, if any, by lexicographical order of the first then the second item in the pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "C3 = apriori(list(L2.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "L3 = LK(dataset,C3,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[frozenset({'DAI62779', 'DAI88079'}), frozenset({'FRO40251'}), 1.0],\n",
       " [frozenset({'ELE17451', 'GRO85051'}), frozenset({'FRO40251'}), 1.0],\n",
       " [frozenset({'GRO73461', 'GRO85051'}), frozenset({'FRO40251'}), 1.0],\n",
       " [frozenset({'ELE26917', 'GRO85051'}), frozenset({'FRO40251'}), 1.0],\n",
       " [frozenset({'GRO85051', 'SNA80324'}), frozenset({'FRO40251'}), 1.0]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supportData_3={}\n",
    "for i,j in L3.items():\n",
    "    supportData_3[i] = j\n",
    "for i,j in L2.items():\n",
    "    supportData_3[i] = j\n",
    "for i,j in L1.items():\n",
    "    supportData_3[i] = j\n",
    "    \n",
    "conf3 = conf_result(supportData_3)\n",
    "conf3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[frozenset({'DAI62779', 'DAI88079'}), frozenset({'FRO40251'}), 1.0],\n",
       " [frozenset({'ELE17451', 'GRO85051'}), frozenset({'FRO40251'}), 1.0],\n",
       " [frozenset({'GRO73461', 'GRO85051'}), frozenset({'FRO40251'}), 1.0],\n",
       " [frozenset({'ELE26917', 'GRO85051'}), frozenset({'FRO40251'}), 1.0],\n",
       " [frozenset({'GRO85051', 'SNA80324'}), frozenset({'FRO40251'}), 1.0]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v for v in conf3 if len(v[0]) == 2][:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dfae695991f40f7f711b859ebe4404a578ce2940a1c2f7058c1cb98bd497b2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
